# 데이터 분할
전체 데이터 세트(`X`)를 학습 데이터 세트, 테스트 데이터 세트로 분리하는 것
- 데이터를 수집하는데 제한성(한계성)이 있기 때문에 데이터 분할이 필요
- 보통 학습 데이터 세트와 테스트 데이터 세트의 비율을 $7:3$ 혹은 $8:3$ 비율로 분할한다.
  - 훈련 데이터 세트의 개수가 어떤 지점 이상 부터는 머신러닝 모델의 성능이 크게 증가하지 않고 비슷하거나 떨어지게 되는 경향이 있다. 그래서 만약 데이터의 양이 충분히 크다면 테스트 데이터 세트의 비율을 더 높여도 괜찮다.

## 1. 훈련 데이터 세트
- 머신러닝 알고리즘의 학습을 위해 사용
- 데이터의 속성(feature_`X_train`)들과 결정값(lable_`y_train`) 모두 가지고 있다.
- **훈련 데이터를 기반으로 머신러닝 알고리즘이 데이터 속성과 결정값의 패턴을 인지하고 학습**
- 머신러닝 모델마다 사용하는 알고리즘이 다르다.

## 2. 테스트 데이터 세트
- 훈련 데이터 세트에서 학습된 머신러닝 알고리즘을 테스트
- 테스트 데이터는 속성 데이터(feature_`X_test`)만 머신러닝 알고리즘에 제공
- 머신러닝 알고리즘은 제공된 데이터를 기반으로 결정값을 예측(`y_train`)
- **테스트 데이터는 학습 데이터와 별도의 데이터 세트로 제공**되어야 한다.
- 일반화 오차 : 테스트 데이터 세트에 대한 오차
  - 머신러닝 모델 훈련의 궁극적인 목적 : 일반화된 모델을 만드는 것
    - 일반화란 과대적합, 과소적합하지 않게 예측하는 것

## 데이터 세트 분리하는 이유
머신러닝 모델 훈련의 목적은 학습된 머신러닝 모델이 새로운 미래의 데이터에 대한 결정값을 예측하게 하고 모델의 예측 성능을 평가할 수 있게 하는 것이다.

만약 가지고 있는 모든 데이터를 머신러닝 모델 훈련을 위해 사용한다면, 머신러닝 모델이 이미 학습한 데이터에 대해 결정값을 예측하기 때문에 해당 모델이 새로운 데이터에 대해 예측을 잘 할 수 있다는 근거가 없다.

따라서 예측을 수행하는 데이터 세트는 학습용 데이터 세트가 아닌 예측 전용의 테스트 데이터 세트여야 한다.

## `train_test_split`
`sklearn.model_selection`의 `train_test_split()`를 이용해 전체 데이터 세트를 학습 데이터 세트와 테스트 데이터 세트로 분리할 수 있다.
- `train_test_split()`을 실행하면 훈련 데이터 세트의 데이터 속성(`X_train`)과 결정값(`y_train`), 테스트 데이터 세트의 데이터 속성(`X_test`)과 결정값(`y_test`) 을 언패킹 상태로 반환한다.
- `train_test_split()`은 데이터를 분할할 때 모든 데이터를 랜덤하게 섞고(shuffle) 분할(split)한다.

```python
import sklearn
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(data, target, test_size, random_state, stratify)
```
* `train_test_split()`의 매개변수
  - `train_test_split()`는 첫 번째 매개변수(parameter)로 feature 데이터 세트, 두 번째 매개변수로 lable 데이터 세트를 입력받는다. 다른 매개변수는 옵션이다.
  - data : feature 데이터 세트
  - target : label 데이터 세트
  - test_size : 전체 데이터에서 테스트 데이터 세트의 비율. 기본값은 0.25로 전체 데이터의 25%를 테스트 세트로 사용한다는 의미
  - random_state :  `train_test_split()`를 실행할 때마다 다른 데이터 세트가 생성될 수 있으므로 난수 값을 고정
    - 동일한 환경에서 동일한 테스트 데이터 세트를 기반으로 머신러닝 모델 튜닝(수정)을 하기 위해 지정한다. 머신러닝 모델 튜닝은 모델의 성능이 더 높아질 수 있게 머신러닝 모델의 기본값을 바꾸는 작업을 말한다.
    - 실무에서는 안정적인 모델의 경우 `random_state`를 사용하지 않는 경우가 많다.
    - 머신러닝에 대한 공부 혹은 연구를 할 경우 `random_state`를 지정하는 것이 좋다.
  - stratify : 데이터 분할 시 원본 데이터의 비율과 동일과 동일하게 테스트 세트를 생성하기 위해 지정하는 데이터 기준

### 데이터를 랜덤하게 섞은 후 데이터 분할을 하는 이유

### 계층적 분할(Stratified Split) 방식

## 학습 데이터 분할
- 훈련 데이터 세트를 다시 분할하여 훈련 데이터 세트와 검증 데이터 세트로 나눈다.
- 검증 데이터 세트는 학습된 모델의 성능을 일차적으로 평가하는 역할을 한다.
- 테스트 데이터 세트는 모든 학습과 검증이 완료된 후 최종적으로 성능을 평가하기 위한 데이터 세트로, 훈련 데이터 세트 및 검증 데이터 세트와 다른 별개의 데이터 세트이다.

## 교차 검증
- 검증 데이터 세트를 여러번 바꿔서 미리 성능 검증을 하는 것
- 훈련 데이터 세트에 해당하는 모든 데이터가 머신러닝 모델의 훈련에도 사용되고, 훈련된 모델의 검증에도 사용된다.

### K Fold 교차 검증
- Fold(폴드) : '접다'는 의미

1. 훈련 데이터 세트를 k개의 폴드 세트로 나눈다
2. k개의 폴드 세트 중 임의의 폴드 세트 1개를 검증 데이터 세트로 설정하고 나머지 k-1개의 폴드 세트를 훈련 데이터 세트로 설정한다.
3. 훈련 데이터 세트로 머신러닝 모델을 학습하고 검증 데이터 세트로 모델을 검증 평가한다.
4. 모든 폴드 세트가 검증 데이터 세트로 사용되도록 k번의 학습과 검증 평가를 반복해서 수행한다.
5. k번의 검증 평가가 완료되면, 검증 평가를 한 k개의 모델의 검증 평가의 평균(mean)을 구하는 교차 검증 최종 평가를 한다.

- 기계적으로 지정한 폴드의 개수 k만큼 데이터를 나누는 방식
- 데이터의 분포를 고려하지 않는다.

### Stratified K Fold 교차 검증
- 불균형한(imbalanced) 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식
- **학습 데이터와 검증 데이터 세트가 가지는 레이블 분포도가 유사하도록 검증 데이터를 추출**

## `cross_val_score`
- K-Fold 클래스를 이용한 교차 검증 방법을 간편화한 사이킷런의 검증 함수
- 폴드 세트 추출, 학습 및 예측, 평가를 한번에 수행할 수 있다.

```python
from sklearn.model_selection import cross_val_score

cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')
```
- `cross_val_score()`의 주요 매개변수는 extimator, X, y, scoring, cv이고 이외의 매개변수는 옵션이다.
  - estimator : 머신러닝 모델. `cross_val_score()`가 분류(Classifier), 회귀(Regressor) 알고리즘 클래스, 즉 모델을 확인하여 적절한 방식의 교차검증을 사용한다.
    - 분류 모델의 경우 Stratified K Fold 방식으로 데이터 분할
    - 회귀 모델의 경우 K Fold 방식으로 데이터 분할
  - X : feature 데이터 세트
  - y : target(lable) 데이터 세트
  - scoring : 예측 성능 평가 방식
  - cv : 교차 검증 폴드의 개수
  - n_jobs : 사용할 CPU의 개수를 의미. -1로 지정할 경우 모든 CPU를 사용한다.

## 하이퍼 파라미터
- 머신러닝의 개별적인 모델에 입력해야 하는 값
- 머신러닝 모델의 설정 값
- 머신러닝 모델이 학습하는 값(훈련 데이터 세트)이 아닌 개발자가 직접 넣어줘야 하는 초기 기본값
- 머신러닝 알고리즘을 구성하는 주요 구성 요소
- 하이퍼 파라미터에 의해 머신러닝 모델의 알고리즘 예측 성능이 조절된다.
  - 즉, 하이퍼 파라미터를 조절해 모델 알고리즘의 최적 튜닝을 할 수 있다.
- 어떤 하이퍼 파라미터의 조합으로 최적의 성능을 가진 모델이 될지 알 수 없기 때문에 계속해서 하이퍼 파라미터를 변경하면서 모델을 수정해야한다.

## `GridSearchCV`
사이킷런에서 제공하는 클래스
- 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에 수행
- 분류, 회귀 모델 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 최적의 파라미터를 도출할 수 있다.
- 하이퍼 파라미터의 모든 조합에 대해 교차 검증을 실행하여 최적의 하이퍼 파라미터를 도출할 수 있다.
```python
from sklearn.model_selection import GridSearchCV

GridSearchCV(estimator, param_grid, cv, refit=True, return_train_score=True)
```

### `GridSearchCV`의 매개 변수
- estimator : 훈련할 머신러닝 모델 
- param_grid : 하이퍼 파리미터의 목록이 들어있는 딕셔너리
  - 여러 개의 딕셔너리를 이용할 수 있다.
  - 딕셔너리의 key : 하이퍼 파라미터의 이름(변수명)
  - 딕셔너리의 value : 하이퍼 파라미터에 들어갈 값의 목록(반드시 리스트로 정의)
- cv : 교차 검증 폴드의 개수
- refit : True로 설정하면 가장 좋은 파라미터 설정으로 재학습시킨다.
- return_train_score : True로 설정하면 훈련 결과 점수를 확인할 수 있다.