{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOkvRFuX7psHp4OEwuyUMGd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 사전학습 모델을 이용한 전이학습"],"metadata":{"id":"hakK3xmy2sNo"}},{"cell_type":"markdown","source":["- 이미지넷 대회에서 `MNIST`, `CRFAR10` 데이터 세트로 우수한 성적을 거둔 모델들을 `Keras`에서 구현되어있음\n","- `Keras`에서 사전학습된 모델을 가져와 데이터에 적용해보겠다."],"metadata":{"id":"KwGQJYxC2v7S"}},{"cell_type":"markdown","source":["## Keras Pretrained Model Loading"],"metadata":{"id":"AtlxDRjr26lD"}},{"cell_type":"code","metadata":{"id":"UDDRa5jAKxwL"},"source":["#from tensorflow.keras.applications.vgg16 import VGG16\n","#from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.applications import VGG16, ResNet50, ResNet50V2, Xception"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633935932904,"user_tz":-540,"elapsed":7204,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"e22b99cb-f29c-4d38-8e18-2041a71b9c71","id":"pjckEuhYq07O"},"source":["# 모델을 불러오면 자동으로 구현된 모델을 확인할 수 있다.\n","# 학습이 안된 모델을 불러올 수 있다.\n","model = VGG16()\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 3s 0us/step\n","553476096/553467096 [==============================] - 3s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["- 직접 특징 추출을 위한 레이어에 대한 조정하는 대신, 사전학습 모델의 특징 추출을 위한 최적의 레이어 세팅을 그대로 사용한다.\n","- 그 이후에 예측을 위한 Full Conected Layer 설계는 원하는 레이어로 지정하여 설계하여 사용하겠다."],"metadata":{"id":"Afx6P3Mz3GW2"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NyAti0ymK6BN","executionInfo":{"status":"ok","timestamp":1633935949053,"user_tz":-540,"elapsed":704,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"07764d49-778b-417e-c5da-4f7169ff585a"},"source":["# weights='imagenet'으로 모델이 학습한 내용을 불러올 수도 있다.\n","model = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 0s 0us/step\n","58900480/58889256 [==============================] - 0s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["- 특징 추출하는 방법 공부잘하는 애꺼쓰고 ㅋ\n","- pollin 예측하는 부분은 내 마음대로 지정해서 수정 가능"],"metadata":{"id":"vV2K4g8FrFV6"}},{"cell_type":"markdown","metadata":{"id":"ZJziSH9nLZC9"},"source":["### Functional Model 확인"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DnSGqu9K_jK","executionInfo":{"status":"ok","timestamp":1633935966957,"user_tz":-540,"elapsed":242,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"d37c655c-d23f-4f2e-f9df-0a1baa00fa58"},"source":["print('model:', model)\n","print('model output:', model.output)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model: <keras.engine.functional.Functional object at 0x7fc360176990>\n","model output: KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 512), dtype=tf.float32, name=None), name='block5_pool/MaxPool:0', description=\"created by layer 'block5_pool'\")\n"]}]},{"cell_type":"markdown","source":["## Pretrained 모델을 기반으로 CIFAR 10 분류 모델 재생성"],"metadata":{"id":"-frPV-_h3n5g"}},{"cell_type":"code","metadata":{"trusted":true,"id":"pbDb7k1AKXZ-"},"source":["IMAGE_SIZE = 32\n","BATCH_SIZE = 64"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### `VGG16` 모델의 최종 특징 추출의 output만 가져오기"],"metadata":{"id":"1hM1O3Cx4PNA"}},{"cell_type":"markdown","source":["### 특징 추출 이후 Full Connected Layer 설정\n","- 평탄화 기법 : `GlobalAveragePooling2D` 사용\n","- 은닉층 : `dense layer` 통과\n","- 출력층 : `dense layer`의 유닛(뉴런)의 개수를 클래스 개수 10으로 지정후 `softmax` 활성화 함수 적용해 최종 output 반환"],"metadata":{"id":"pZSM7aHo4deW"}},{"cell_type":"markdown","source":["### 모델 생성\n","- 입력 데이터를 사전학습 모델의 특정 추출값과 설정한 Full Conncevted Layer를 통과하여 모델 생성"],"metadata":{"id":"LpNlsva-5CKg"}},{"cell_type":"code","metadata":{"trusted":true,"id":"_rSiE4M1KXZ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633936237181,"user_tz":-540,"elapsed":356,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"c8e01800-5912-49cf-beb8-cb3d9470f435"},"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","\n","# include_top=False로 기존 imagenet용 classifier 층들을 다 제거. weight는 전이학습을 위해 imagenet 학습된 weight를 초기 weight로 사용.\n","#input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","#base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n","\n","base_model = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n","bm_output = base_model.output # Feature Extraction의 마지막 부분을 의미(최종 특징 추출 단계)\n","\n","# base model의 output을 입력으로 CIFAR10용 Classification layer를 재 구성.\n","# Flatten 레이어를 GlobalAveragePooling2D로 변경\n","x = GlobalAveragePooling2D()(bm_output) # GAP :  평탄화 기법 중 하나\n","# x = Dropout(rate=0.5)(x)\n","x = Dense(50, activation='relu', name='fc1')(x)\n","# x = Dropout(rate=0.2)(x)\n","output = Dense(10, activation='softmax', name='output')(x)\n","\n","#model = Model(inputs=input_tensor, outputs=output)\n","model = Model(inputs=base_model.input, outputs=output)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 512)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 50)                25650     \n","_________________________________________________________________\n","output (Dense)               (None, 10)                510       \n","=================================================================\n","Total params: 14,740,848\n","Trainable params: 14,740,848\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["- 평탄화 기법\n","1. `Flattern()`\n","  - 채널 수가 512개 미만일 경우 사용(논문 결과)\n","2. `GlobalAveragePoolin2D()`\n","  - 채널 수가 512개 이상일 경우 사용\n","  - 채널 수가 512개 이상일 때 `Flattern()` 단점이 커지기 때문에 대안으로 나온 평탄화기법\n","  - 각 채널별 피처맵 데이터의 평균을 구한다.\n","- 각 데이터의 모양이 (7, 7, 512)일 때\n","  - `Flattern()`으로 평탄화하면 $7*7*512$개의 데이터가 나오고\n","  - `GlobalAveragePoolin2D()`으로 평탄화하면 512개 나온다."],"metadata":{"id":"j4MyMbqe5YH9"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"PfjCJ-fB63ax"}},{"cell_type":"markdown","source":["## 데이터 전처리"],"metadata":{"id":"r5AkS4iO5pSU"}},{"cell_type":"markdown","source":["### 데이터 전처리를 위한 함수 정의"],"metadata":{"id":"6r9HUdCH52CM"}},{"cell_type":"code","source":[],"metadata":{"id":"InuFAGE59qcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"_QIkTIWpKXZ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633936253377,"user_tz":-540,"elapsed":6920,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"89a2586f-3610-48fd-ef57-224b3b5130ba"},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","\n","import random as python_random\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets import cifar10\n","\n","# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음.\n","def set_random_seed(seed_value):\n","    np.random.seed(seed_value)\n","    python_random.seed(seed_value)\n","    tf.random.set_seed(seed_value)\n","\n","# 0 ~ 1사이값의 float32로 변경하는 함수\n","def get_preprocessed_data(images, labels, scaling=True):\n","\n","    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형.\n","    if scaling:\n","        images = np.array(images/255.0, dtype=np.float32)\n","    else:\n","        images = np.array(images, dtype=np.float32)\n","\n","    labels = np.array(labels, dtype=np.float32)\n","\n","    return images, labels\n","\n","# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용\n","def get_preprocessed_ohe(images, labels):\n","    images, labels = get_preprocessed_data(images, labels, scaling=False)\n","    # OHE 적용\n","    oh_labels = to_categorical(labels)\n","    return images, oh_labels\n","\n","# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환\n","def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n","    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용.\n","    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n","    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n","\n","    # 학습 데이터를 검증 데이터 세트로 다시 분리\n","    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n","\n","    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels )\n","\n","\n","# random seed는 2021로 고정.\n","set_random_seed(2021)\n","# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성.\n","(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n","\n","(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n","    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n","\n","print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n","170508288/170498071 [==============================] - 4s 0us/step\n","(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n","(42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n"]}]},{"cell_type":"markdown","source":["## ImageDataGenerator로 Augmentation 설정하고 학습용, 검증용 Generator 생성"],"metadata":{"id":"MKKGhHJt6oL-"}},{"cell_type":"markdown","source":["## Keras CNN 모델 생성 함수 정의"],"metadata":{"id":"0EuMyr2K6w2f"}},{"cell_type":"code","source":["IMAGE_SIZE = 32\n","BATCH_SIZE = 64"],"metadata":{"id":"0QXu2Toq60KX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","\n","def create_model(verbose=False):\n","\n","    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","    base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n","    bm_output = base_model.output\n","\n","    x = GlobalAveragePooling2D()(bm_output)\n","    #x = Dropout(rate=0.5)(x)\n","    x = Dense(50, activation='relu', name='fc1')(x)\n","    #x = Dropout(rate=0.2)(x)\n","    output = Dense(10, activation='softmax', name='output')(x)\n","\n","    model = Model(inputs=input_tensor, outputs=output)\n","    if verbose:\n","        model.summary()\n","\n","    return model"],"metadata":{"id":"OWgpPOLT61ID"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 생성 및 모델 컴파일\n","-  모델의 훈련을 위한 손실함수, 최적화. 평가지표를 지정하는 컴파일 작업 수행\n","\n"],"metadata":{"id":"21sZALmw68md"}},{"cell_type":"code","metadata":{"trusted":true,"id":"kbaNM3QHKXaB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633936270383,"user_tz":-540,"elapsed":593,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"48117172-c913-4b9a-d5b1-adb2013ce48f"},"source":["vgg_model = create_model(verbose=True)\n","vgg_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.\n","rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n","# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n","ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 512)               0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 50)                25650     \n","_________________________________________________________________\n","output (Dense)               (None, 10)                510       \n","=================================================================\n","Total params: 14,740,848\n","Trainable params: 14,740,848\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"trusted":true,"id":"jrOodDfqKXaB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633936734716,"user_tz":-540,"elapsed":460240,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"296839c7-f11a-4da8-f52a-912e42d2f405"},"source":["# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)\n","tr_data_len = tr_images.shape[0]\n","val_data_len = val_images.shape[0]\n","history = vgg_model.fit(flow_tr_gen, epochs=40,\n","                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)),\n","                    validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n","                    callbacks=[rlr_cb, ely_cb])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","665/665 [==============================] - 33s 25ms/step - loss: 1.8729 - accuracy: 0.2488 - val_loss: 1.5167 - val_accuracy: 0.3848\n","Epoch 2/40\n","665/665 [==============================] - 16s 24ms/step - loss: 1.3315 - accuracy: 0.4856 - val_loss: 1.2003 - val_accuracy: 0.5732\n","Epoch 3/40\n","665/665 [==============================] - 16s 24ms/step - loss: 1.0117 - accuracy: 0.6471 - val_loss: 0.9944 - val_accuracy: 0.6601\n","Epoch 4/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.8379 - accuracy: 0.7173 - val_loss: 0.8373 - val_accuracy: 0.7353\n","Epoch 5/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.7415 - accuracy: 0.7530 - val_loss: 0.7109 - val_accuracy: 0.7689\n","Epoch 6/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.6593 - accuracy: 0.7823 - val_loss: 0.6537 - val_accuracy: 0.7891\n","Epoch 7/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.6022 - accuracy: 0.8024 - val_loss: 0.6326 - val_accuracy: 0.7985\n","Epoch 8/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.5436 - accuracy: 0.8223 - val_loss: 0.6918 - val_accuracy: 0.7783\n","Epoch 9/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.5236 - accuracy: 0.8282 - val_loss: 0.6139 - val_accuracy: 0.8017\n","Epoch 10/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.4668 - accuracy: 0.8484 - val_loss: 0.5646 - val_accuracy: 0.8229\n","Epoch 11/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.4273 - accuracy: 0.8626 - val_loss: 0.5906 - val_accuracy: 0.8149\n","Epoch 12/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.4076 - accuracy: 0.8679 - val_loss: 0.5419 - val_accuracy: 0.8312\n","Epoch 13/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.3852 - accuracy: 0.8744 - val_loss: 0.6246 - val_accuracy: 0.8216\n","Epoch 14/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.3533 - accuracy: 0.8860 - val_loss: 0.5458 - val_accuracy: 0.8300\n","Epoch 15/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.3379 - accuracy: 0.8923 - val_loss: 0.6152 - val_accuracy: 0.8296\n","Epoch 16/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.3265 - accuracy: 0.8963 - val_loss: 0.5543 - val_accuracy: 0.8325\n","Epoch 17/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.3119 - accuracy: 0.8994 - val_loss: 0.5638 - val_accuracy: 0.8332\n","\n","Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","Epoch 18/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.1771 - accuracy: 0.9434 - val_loss: 0.5309 - val_accuracy: 0.8621\n","Epoch 19/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.1278 - accuracy: 0.9596 - val_loss: 0.5647 - val_accuracy: 0.8620\n","Epoch 20/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.1025 - accuracy: 0.9689 - val_loss: 0.5990 - val_accuracy: 0.8605\n","Epoch 21/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.0877 - accuracy: 0.9740 - val_loss: 0.6083 - val_accuracy: 0.8609\n","Epoch 22/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.0670 - accuracy: 0.9803 - val_loss: 0.6955 - val_accuracy: 0.8604\n","Epoch 23/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.0591 - accuracy: 0.9828 - val_loss: 0.7230 - val_accuracy: 0.8581\n","\n","Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","Epoch 24/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.0400 - accuracy: 0.9892 - val_loss: 0.7299 - val_accuracy: 0.8619\n","Epoch 25/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.0276 - accuracy: 0.9925 - val_loss: 0.7918 - val_accuracy: 0.8624\n","Epoch 26/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.8417 - val_accuracy: 0.8600\n","Epoch 27/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.8927 - val_accuracy: 0.8627\n","Epoch 28/40\n","665/665 [==============================] - 16s 24ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.9374 - val_accuracy: 0.8632\n","\n","Epoch 00028: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","Epoch 00028: early stopping\n"]}]},{"cell_type":"code","metadata":{"trusted":true,"id":"Nkgr2DiYKXaB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633936735908,"user_tz":-540,"elapsed":1196,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"8305de81-97fa-42f3-ec64-9e31a80c8994"},"source":["test_generator = ImageDataGenerator(rescale=1/255.0)\n","flow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n","vgg_model.evaluate(flow_test_gen)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["157/157 [==============================] - 1s 9ms/step - loss: 1.0857 - accuracy: 0.8472\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.085679292678833, 0.8471999764442444]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"trusted":true,"id":"JHEQ7bOUKXaC","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1633936736344,"user_tz":-540,"elapsed":437,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"14a5b5bc-6cc7-4669-fb65-87e9e6ca378e"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def show_history(history):\n","    plt.figure(figsize=(8, 4))\n","    plt.yticks(np.arange(0, 1, 0.05))\n","    plt.xticks(np.arange(0, 30, 2))\n","    plt.plot(history.history['accuracy'], label='train')\n","    plt.plot(history.history['val_accuracy'], label='valid')\n","    plt.legend()\n","\n","show_history(history)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## [총정리] 지금까지의 로직들을 함수화"],"metadata":{"id":"OeJ6sWIv7qyt"}},{"cell_type":"code","metadata":{"trusted":true,"id":"qrCZi9idKXaC"},"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop\n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import cv2\n","\n","import random as python_random\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets import cifar10\n","\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.applications import ResNet50V2\n","from tensorflow.keras.applications import Xception\n","\n","# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음.\n","def set_random_seed(seed_value):\n","    np.random.seed(seed_value)\n","    python_random.seed(seed_value)\n","    tf.random.set_seed(seed_value)\n","\n","# 0 ~ 1사이값의 float32로 변경하는 함수\n","def get_preprocessed_data(images, labels, scaling=True):\n","\n","    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형.\n","    if scaling:\n","        images = np.array(images/255.0, dtype=np.float32)\n","    else:\n","        images = np.array(images, dtype=np.float32)\n","\n","    labels = np.array(labels, dtype=np.float32)\n","\n","    return images, labels\n","\n","# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용\n","def get_preprocessed_ohe(images, labels):\n","    images, labels = get_preprocessed_data(images, labels, scaling=False)\n","    # OHE 적용\n","    oh_labels = to_categorical(labels)\n","    return images, oh_labels\n","\n","# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환\n","def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n","    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용.\n","    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n","    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n","\n","    # 학습 데이터를 검증 데이터 세트로 다시 분리\n","    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n","\n","    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels )\n","\n","# 입력 image의 크기를 resize 값 만큼 증가. CIFAR10의 이미지가 32x32로 작아서 마지막 feature map의 크기가 1로 되어 모델 성능이 좋지 않음.\n","# 마지막 feature map의 크기를 2로 만들기 위해 resize를 64로 하여 입력 이미지 크기를 변경. 단 메모리를 크게 소비하므로 64이상은 kernel이 다운됨.\n","def get_resized_images(images, resize=64):\n","    image_cnt = images.shape[0]\n","    resized_images = np.zeros((images.shape[0], resize, resize, 3))\n","    for i in range(image_cnt):\n","        resized_image = cv2.resize(images[i], (resize, resize))\n","        resized_images[i] = resized_image\n","\n","    return resized_images\n","\n","def create_model(model_name='vgg16', verbose=False):\n","\n","    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","    if model_name == 'vgg16':\n","        base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n","    elif model_name == 'resnet50':\n","        base_model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n","    elif model_name == 'xception':\n","        base_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n","\n","    bm_output = base_model.output\n","\n","    x = GlobalAveragePooling2D()(bm_output)\n","    if model_name != 'vgg16':\n","        x = Dropout(rate=0.5)(x)\n","    x = Dense(50, activation='relu', name='fc1')(x)\n","    output = Dense(10, activation='softmax', name='output')(x)\n","\n","    model = Model(inputs=input_tensor, outputs=output)\n","    model.summary()\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"PKmasDvFKXaC"},"source":["IMAGE_SIZE = 32\n","BATCH_SIZE = 64\n","\n","def do_cifar10_train_evaluation(image_size=IMAGE_SIZE, model_name='vgg16'):\n","    set_random_seed(2021)\n","    # CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성.\n","    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","    (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n","        get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n","    print('데이터 세트 shape:', tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)\n","\n","    # 만약 image_size가 32보다 크면 이미지 크기 재조정.\n","    if image_size > 32:\n","        tr_images = get_resized_images(tr_images)\n","        val_images = get_resized_images(val_images)\n","        test_images = get_resized_images(test_images)\n","\n","    # 학습/검증/테스트용 ImageDataGenerator와 flow로 pipeline 생성.\n","    train_generator = ImageDataGenerator(\n","        horizontal_flip=True,\n","        rescale=1/255.0\n","    )\n","    valid_generator = ImageDataGenerator(rescale=1/255.0)\n","    test_generator = ImageDataGenerator(rescale=1/255.0)\n","\n","    flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n","    flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n","    flow_test_gen = train_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    # model_name 에 따른 모델 생성하고 모델 학습 및 검증 수행.\n","    model = create_model(model_name=model_name, verbose=True)\n","    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    # 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.\n","    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n","    # 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n","    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n","\n","    tr_data_len = tr_images.shape[0]\n","    val_data_len = val_images.shape[0]\n","    history = model.fit(flow_tr_gen, epochs=40,\n","                        steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)),\n","                        validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n","                        callbacks=[rlr_cb, ely_cb])\n","    # 테스트 데이터 세트로 모델 성능 검증\n","    evaluation_result = model.evaluate(flow_test_gen)\n","    print('테스트 데이터 세트 evaluation 결과:', evaluation_result)\n","    return history, evaluation_result\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"tJLMAwc9KXaD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633936737520,"user_tz":-540,"elapsed":2,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"25c0c61f-0b39-4167-d1fe-ca2857d2edd0"},"source":["import gc\n","\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3916"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"trusted":true,"id":"LMytAvIkKXaD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633938154301,"user_tz":-540,"elapsed":1416783,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"55fa72e1-194c-45dc-ba30-4a48bc4c1776"},"source":["# 만약 image_size를 64로 하려면 반드시 RAM이 여유분이 충분히 있는지 확인 후 진행\n","history, evaluation_result = do_cifar10_train_evaluation(image_size=64, model_name='xception')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 세트 shape: (42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 0s 0us/step\n","83697664/83683744 [==============================] - 0s 0us/step\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_5 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 15, 15, 32)   864         input_5[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 15, 15, 32)   128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 15, 15, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 13, 13, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 13, 13, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 13, 13, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 13, 13, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 13, 13, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 13, 13, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 7, 7, 128)    8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 7, 7, 128)    0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 7, 7, 128)    512         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 7, 7, 128)    0           block2_pool[0][0]                \n","                                                                 batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 7, 7, 128)    0           add[0][0]                        \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 7, 7, 256)    33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 7, 7, 256)    0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 7, 7, 256)    67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 4, 4, 256)    32768       add[0][0]                        \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 4, 4, 256)    1024        conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 4, 4, 256)    0           block3_pool[0][0]                \n","                                                                 batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 4, 4, 256)    0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 4, 4, 728)    188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 4, 4, 728)    0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 2, 2, 728)    186368      add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 2, 2, 728)    0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 2, 2, 728)    2912        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 2, 2, 728)    0           block4_pool[0][0]                \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 2, 2, 728)    0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 2, 2, 728)    0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 2, 2, 728)    0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 2, 2, 728)    0           block5_sepconv3_bn[0][0]         \n","                                                                 add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 2, 2, 728)    0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 2, 2, 728)    0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 2, 2, 728)    0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 2, 2, 728)    0           block6_sepconv3_bn[0][0]         \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 2, 2, 728)    0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 2, 2, 728)    0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 2, 2, 728)    0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 2, 2, 728)    0           block7_sepconv3_bn[0][0]         \n","                                                                 add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 2, 2, 728)    0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 2, 2, 728)    0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 2, 2, 728)    0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 2, 2, 728)    0           block8_sepconv3_bn[0][0]         \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 2, 2, 728)    0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 2, 2, 728)    0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 2, 2, 728)    0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 2, 2, 728)    0           block9_sepconv3_bn[0][0]         \n","                                                                 add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 2, 2, 728)    0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 2, 2, 728)    0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 2, 2, 728)    0           block10_sepconv3_bn[0][0]        \n","                                                                 add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 2, 2, 728)    0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 2, 2, 728)    0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 2, 2, 728)    0           block11_sepconv3_bn[0][0]        \n","                                                                 add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 2, 2, 728)    0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 2, 2, 728)    0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 2, 2, 728)    0           block12_sepconv3_bn[0][0]        \n","                                                                 add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 2, 2, 728)    0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 2, 2, 1024)   752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 2, 2, 1024)   4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 1, 1, 1024)   745472      add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 1, 1, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 1, 1, 1024)   4096        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 1, 1, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 1, 1, 1536)   1582080     add_11[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 1, 1, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 1, 1, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 1, 1, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 1, 1, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 1, 1, 2048)   0           block14_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","global_average_pooling2d_2 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 2048)         0           global_average_pooling2d_2[0][0] \n","__________________________________________________________________________________________________\n","fc1 (Dense)                     (None, 50)           102450      dropout[0][0]                    \n","__________________________________________________________________________________________________\n","output (Dense)                  (None, 10)           510         fc1[0][0]                        \n","==================================================================================================\n","Total params: 20,964,440\n","Trainable params: 20,909,912\n","Non-trainable params: 54,528\n","__________________________________________________________________________________________________\n","Epoch 1/40\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]},{"output_type":"stream","name":"stdout","text":["665/665 [==============================] - 53s 74ms/step - loss: 0.7484 - accuracy: 0.7533 - val_loss: 0.5515 - val_accuracy: 0.8324\n","Epoch 2/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.4046 - accuracy: 0.8676 - val_loss: 0.6244 - val_accuracy: 0.8137\n","Epoch 3/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.3103 - accuracy: 0.8982 - val_loss: 0.4075 - val_accuracy: 0.8723\n","Epoch 4/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.2555 - accuracy: 0.9146 - val_loss: 0.6146 - val_accuracy: 0.8325\n","Epoch 5/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.2379 - accuracy: 0.9223 - val_loss: 0.3721 - val_accuracy: 0.8840\n","Epoch 6/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.1744 - accuracy: 0.9441 - val_loss: 0.3735 - val_accuracy: 0.8888\n","Epoch 7/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.1491 - accuracy: 0.9512 - val_loss: 0.3996 - val_accuracy: 0.8769\n","Epoch 8/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.1326 - accuracy: 0.9561 - val_loss: 0.7989 - val_accuracy: 0.8099\n","Epoch 9/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.2090 - accuracy: 0.9321 - val_loss: 0.3127 - val_accuracy: 0.9052\n","Epoch 10/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.1261 - accuracy: 0.9580 - val_loss: 0.3655 - val_accuracy: 0.8951\n","Epoch 11/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.0921 - accuracy: 0.9704 - val_loss: 0.3195 - val_accuracy: 0.9123\n","Epoch 12/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.0872 - accuracy: 0.9715 - val_loss: 0.3481 - val_accuracy: 0.9032\n","Epoch 13/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.0874 - accuracy: 0.9709 - val_loss: 0.3105 - val_accuracy: 0.9072\n","Epoch 14/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.0687 - accuracy: 0.9779 - val_loss: 0.3669 - val_accuracy: 0.9059\n","Epoch 15/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.0859 - accuracy: 0.9729 - val_loss: 0.3508 - val_accuracy: 0.9071\n","Epoch 16/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.0719 - accuracy: 0.9769 - val_loss: 1.9139 - val_accuracy: 0.5269\n","Epoch 17/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.0943 - accuracy: 0.9684 - val_loss: 0.3169 - val_accuracy: 0.9147\n","Epoch 18/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.0547 - accuracy: 0.9824 - val_loss: 0.3398 - val_accuracy: 0.9073\n","\n","Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","Epoch 19/40\n","665/665 [==============================] - 48s 72ms/step - loss: 0.0241 - accuracy: 0.9925 - val_loss: 0.2611 - val_accuracy: 0.9363\n","Epoch 20/40\n","665/665 [==============================] - 48s 72ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.2756 - val_accuracy: 0.9412\n","Epoch 21/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.2966 - val_accuracy: 0.9377\n","Epoch 22/40\n","665/665 [==============================] - 48s 72ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.3126 - val_accuracy: 0.9380\n","Epoch 23/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.3175 - val_accuracy: 0.9388\n","Epoch 24/40\n","665/665 [==============================] - 48s 73ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.3349 - val_accuracy: 0.9388\n","\n","Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","Epoch 25/40\n","665/665 [==============================] - 48s 72ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.3269 - val_accuracy: 0.9391\n","Epoch 26/40\n","665/665 [==============================] - 48s 72ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.3269 - val_accuracy: 0.9397\n","Epoch 27/40\n","665/665 [==============================] - 48s 72ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.3299 - val_accuracy: 0.9412\n","Epoch 28/40\n","665/665 [==============================] - 48s 72ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.3355 - val_accuracy: 0.9415\n","Epoch 29/40\n","665/665 [==============================] - 48s 72ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3390 - val_accuracy: 0.9413\n","\n","Epoch 00029: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","Epoch 00029: early stopping\n","157/157 [==============================] - 3s 19ms/step - loss: 0.3842 - accuracy: 0.9329\n","테스트 데이터 세트 evaluation 결과: [0.3841651678085327, 0.9329000115394592]\n"]}]},{"cell_type":"code","metadata":{"trusted":true,"id":"qLNYfxcTKXaD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633938154301,"user_tz":-540,"elapsed":7,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"ecc1a901-fe65-4ca0-94bf-5dd2ecb6b924"},"source":["print('테스트 데이터세트 검증 결과:', evaluation_result)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["테스트 데이터세트 검증 결과: [0.3841651678085327, 0.9329000115394592]\n"]}]},{"cell_type":"code","metadata":{"trusted":true,"id":"F7hDBATFKXaD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633938154938,"user_tz":-540,"elapsed":639,"user":{"displayName":"소민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh54_mzlnkVqFMNEtkS9whNdrQKRT0BTwpIESQjOQ=s64","userId":"13788803923072454204"}},"outputId":"23e8af36-2434-4c3b-c91f-5a154eea37ef"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def show_history(history):\n","    plt.figure(figsize=(8, 4))\n","    plt.yticks(np.arange(0, 1, 0.05))\n","    plt.xticks(np.arange(0, 30, 2))\n","    plt.plot(history.history['accuracy'], label='train')\n","    plt.plot(history.history['val_accuracy'], label='valid')\n","    plt.legend()\n","\n","show_history(history)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]}]}